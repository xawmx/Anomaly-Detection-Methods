{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d65ed2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import networkx as nx\n",
    "import pickle\n",
    "from itertools import combinations\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import train_test_split_edges, degree\n",
    "\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5387f9",
   "metadata": {},
   "source": [
    "## 数据读入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c80fff4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"dataset\\\\\"\n",
    "graph_id = 3\n",
    "\n",
    "pklfile_tx_sort = dataset + f\"EthereumG{graph_id}\\\\LPsubG{graph_id}\" + \"_df_sort.pickle\"\n",
    "\n",
    "df_tx = pd.read_pickle(pklfile_tx_sort)\n",
    "df_tx['From'] = df_tx['From'].astype(int)\n",
    "df_tx['To'] = df_tx['To'].astype(int)\n",
    "df_tx['TimeStamp'] = df_tx['TimeStamp'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a147795b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>From</th>\n",
       "      <th>To</th>\n",
       "      <th>Value</th>\n",
       "      <th>TimeStamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9435</td>\n",
       "      <td>1773</td>\n",
       "      <td>1670.000000</td>\n",
       "      <td>1438269973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9435</td>\n",
       "      <td>6547</td>\n",
       "      <td>101.230000</td>\n",
       "      <td>1438269973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9435</td>\n",
       "      <td>1885</td>\n",
       "      <td>1200.000000</td>\n",
       "      <td>1438269973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9435</td>\n",
       "      <td>1886</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>1438269973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9435</td>\n",
       "      <td>1887</td>\n",
       "      <td>370.000000</td>\n",
       "      <td>1438269973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1359143</th>\n",
       "      <td>1778</td>\n",
       "      <td>3063</td>\n",
       "      <td>1.000658</td>\n",
       "      <td>1547762069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1359144</th>\n",
       "      <td>1405</td>\n",
       "      <td>5844</td>\n",
       "      <td>0.200106</td>\n",
       "      <td>1547763634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1359145</th>\n",
       "      <td>77942</td>\n",
       "      <td>2985</td>\n",
       "      <td>0.101029</td>\n",
       "      <td>1547764823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1359146</th>\n",
       "      <td>1405</td>\n",
       "      <td>142</td>\n",
       "      <td>0.201796</td>\n",
       "      <td>1547782857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1359147</th>\n",
       "      <td>1402</td>\n",
       "      <td>6661</td>\n",
       "      <td>0.687420</td>\n",
       "      <td>1547807130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1359148 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          From    To        Value   TimeStamp\n",
       "0         9435  1773  1670.000000  1438269973\n",
       "1         9435  6547   101.230000  1438269973\n",
       "2         9435  1885  1200.000000  1438269973\n",
       "3         9435  1886   800.000000  1438269973\n",
       "4         9435  1887   370.000000  1438269973\n",
       "...        ...   ...          ...         ...\n",
       "1359143   1778  3063     1.000658  1547762069\n",
       "1359144   1405  5844     0.200106  1547763634\n",
       "1359145  77942  2985     0.101029  1547764823\n",
       "1359146   1405   142     0.201796  1547782857\n",
       "1359147   1402  6661     0.687420  1547807130\n",
       "\n",
       "[1359148 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e908d1af",
   "metadata": {},
   "source": [
    "## 数据集统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbf947e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_statistics(df):\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    min_time = sys.maxsize\n",
    "    max_time = 0\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        x = int(row['From'])\n",
    "        y = int(row['To'])\n",
    "        a = row['Value']\n",
    "        t = int(row['TimeStamp'])\n",
    "        \n",
    "        if G.has_edge(x, y):\n",
    "            G[x][y]['weight'] += a                        \n",
    "        else:    \n",
    "            G.add_edge(x, y, timestamp=t, weight=a)     \n",
    "                    \n",
    "        if t < min_time:\n",
    "            min_time = t\n",
    "        elif t > max_time:\n",
    "            max_time = t  \n",
    "\n",
    "    num_nodes = G.number_of_nodes()  # 节点数量\n",
    "    num_edges = G.number_of_edges()  # 边数量\n",
    "\n",
    "    avg_degree = np.mean([deg for node, deg in G.degree()])  # 平均度数\n",
    "    \n",
    "    avg_clustering_coefficient = nx.average_clustering(G)  # 平均聚类系数\n",
    "\n",
    "    time_span = max_time - min_time  # 时间跨度\n",
    "\n",
    "    print(f'Number of nodes: {num_nodes}')\n",
    "    print(f'Number of edges: {num_edges}')\n",
    "    print(f'Average degree: {avg_degree:.3f}')\n",
    "    print(f'Average clustering coefficient: {avg_clustering_coefficient:.3f}')\n",
    "    print(f'Transaction time span: {time_span} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03809c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 103916\n",
      "Number of edges: 118440\n",
      "Average degree: 2.280\n",
      "Average clustering coefficient: 0.016\n",
      "Transaction time span: 109537157 seconds\n"
     ]
    }
   ],
   "source": [
    "# df_tx.drop(0, inplace = True) # 针对EthereumG1\n",
    "\n",
    "graph_statistics(df_tx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85809029",
   "metadata": {},
   "source": [
    "## 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ded76bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding data shape: (951403, 4)\n",
      "Train and Test data shape (filtered): (279581, 4)\n"
     ]
    }
   ],
   "source": [
    "total_rows = len(df_tx)\n",
    "\n",
    "# 划分数据集的三个部分：%用于生成节点嵌入，%用于训练和测试\n",
    "emb_ratio = 0.7\n",
    "emb_end = int(total_rows * emb_ratio)\n",
    "\n",
    "# 取出前 % 和后 % 数据\n",
    "df_emb = df_tx.iloc[:emb_end]\n",
    "df_train_test = df_tx.iloc[emb_end:]\n",
    "\n",
    "# 获取前 % 数据中的所有节点（From 和 To 列）\n",
    "emb_nodes = set(df_emb['From']).union(set(df_emb['To']))\n",
    "\n",
    "# 确保用于训练和测试的交易中所涉及的节点存在嵌入\n",
    "df_train_test_filtered = df_train_test[df_train_test['From'].isin(emb_nodes) & df_train_test['To'].isin(emb_nodes)]\n",
    "\n",
    "# 打印划分后的数据\n",
    "print(f\"Embedding data shape: {df_emb.shape}\")\n",
    "print(f\"Train and Test data shape (filtered): {df_train_test_filtered.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c723dfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_neg_edges(edges_pos, nodes, neg_samples_per_pos=1):    \n",
    "    edges_neg = []\n",
    "\n",
    "    # 随机采样负样本\n",
    "    while len(edges_neg) < len(edges_pos) * neg_samples_per_pos:\n",
    "        # 随机选择一个节点对 (i, j)\n",
    "        i = random.choice(nodes)\n",
    "        j = random.choice(nodes)\n",
    "        \n",
    "        # 确保节点对 (i, j) 不相等并且不是正样本\n",
    "        if i != j and (i, j) not in edges_pos and (j, i) not in edges_pos:\n",
    "            edges_neg.append((i, j))\n",
    "\n",
    "    return edges_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "2bf69e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of positive Train Test edges: 4677\n",
      "Num of negative Train Test edges: 4677\n"
     ]
    }
   ],
   "source": [
    "# 获取训练测试交易集的所有节点\n",
    "train_test_nodes = list(set(df_train_test_filtered['From']).union(set(df_train_test_filtered['To'])))\n",
    "\n",
    "# 获取训练测试交易集的所有边，保证训练测试边集的数据唯一性，并打乱时间顺序\n",
    "train_test_edges_pos = list(set(zip(df_train_test_filtered['From'], df_train_test_filtered['To'])))\n",
    "random.shuffle(train_test_edges_pos)\n",
    "\n",
    "# 随机采样负样本\n",
    "train_test_edges_neg = sample_neg_edges(train_test_edges_pos, train_test_nodes)\n",
    "\n",
    "print(\"Num of positive Train Test edges:\", len(train_test_edges_pos))\n",
    "print(\"Num of negative Train Test edges:\", len(train_test_edges_neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5c6a1546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of positive Train edges: 2338\n",
      "Num of negative Train edges: 2338\n",
      "Num of positive Test edges: 2339\n",
      "Num of negative Test edges: 2339\n"
     ]
    }
   ],
   "source": [
    "# 划分为训练集（50%）和测试集（50%）\n",
    "train_pos_size = int(len(train_test_edges_pos) * 0.5)\n",
    "train_neg_size = int(len(train_test_edges_neg) * 0.5)\n",
    "\n",
    "\n",
    "# 训练集\n",
    "train_edges_pos = train_test_edges_pos[:train_pos_size]\n",
    "train_edges_neg = train_test_edges_neg[:train_neg_size]\n",
    "\n",
    "# 测试集\n",
    "test_edges_pos = train_test_edges_pos[train_pos_size:]\n",
    "test_edges_neg = train_test_edges_neg[train_neg_size:]\n",
    "\n",
    "print(\"Num of positive Train edges:\", len(train_edges_pos))\n",
    "print(\"Num of negative Train edges:\", len(train_edges_neg))\n",
    "print(\"Num of positive Test edges:\", len(test_edges_pos))\n",
    "print(\"Num of negative Test edges:\", len(test_edges_neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "51fdc5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_edges = {}\n",
    "train_test_edges['train_edges_pos'] = train_edges_pos\n",
    "train_test_edges['train_edges_false'] = train_edges_neg\n",
    "train_test_edges['test_edges_pos'] = test_edges_pos\n",
    "train_test_edges['test_edges_false'] = test_edges_neg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6cba36",
   "metadata": {},
   "source": [
    "read or write processed data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92cc9485",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_id = 3\n",
    "emb_ratio = 0.7\n",
    "\n",
    "data_path = \"dataset\\\\\"\n",
    "pklfile_emb = data_path + f\"LPsubG{graph_id}_df_emb_{emb_ratio}.pickle\"\n",
    "pklfile_train_test_edges = data_path + f\"LPsubG{graph_id}_train_test_edges_{emb_ratio}.pickle\"\n",
    "\n",
    "# 写\n",
    "# df_emb.to_pickle(pklfile_emb)\n",
    "# with open(pklfile_train_test_edges, 'wb') as f:\n",
    "#     pickle.dump(train_test_edges, f)\n",
    "\n",
    "# 读    \n",
    "df_emb = pd.read_pickle(pklfile_emb)\n",
    "if os.path.exists(pklfile_train_test_edges):    \n",
    "    with open( pklfile_train_test_edges,\"rb\") as f:     \n",
    "        train_test_edges = pickle.load(f)\n",
    "        train_edges_pos = train_test_edges['train_edges_pos']\n",
    "        train_edges_neg = train_test_edges['train_edges_false']\n",
    "        test_edges_pos = train_test_edges['test_edges_pos']\n",
    "        test_edges_neg = train_test_edges['test_edges_false'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb771a46",
   "metadata": {},
   "source": [
    "## 特征提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62283bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_account_features(df_tx, is_df=True):\n",
    "    # 初始化账户统计信息\n",
    "    account_features = {}\n",
    "\n",
    "    # 遍历交易数据，更新统计信息\n",
    "    for idx, tx in df_tx.iterrows():\n",
    "        sender = int(tx[\"From\"])\n",
    "        receiver = int(tx[\"To\"])\n",
    "        amount = tx[\"Value\"]\n",
    "        timestamp = int(tx[\"TimeStamp\"])\n",
    "\n",
    "        # 更新发送方信息\n",
    "        if sender not in account_features:\n",
    "            account_features[sender] = {\"in_txs\": 0,  \"in_amount\": 0, \\\n",
    "                                     \"out_txs\": 0,  \"out_amount\": 0,\\\n",
    "                                     \"first_active\": timestamp, \"last_active\": timestamp}\n",
    "        account_features[sender][\"out_txs\"] += 1\n",
    "        account_features[sender][\"out_amount\"] += amount\n",
    "        if timestamp < account_features[sender][\"first_active\"]:\n",
    "            account_features[sender][\"first_active\"] = timestamp\n",
    "        if timestamp > account_features[sender][\"last_active\"]:\n",
    "            account_features[sender][\"last_active\"] = timestamp\n",
    "\n",
    "\n",
    "        # 更新接收方信息\n",
    "        if receiver not in account_features:\n",
    "            account_features[receiver] = {\"in_txs\": 0,  \"in_amount\": 0, \\\n",
    "                                     \"out_txs\": 0, \"out_amount\": 0, \\\n",
    "                                     \"first_active\": timestamp, \"last_active\": timestamp}\n",
    "        account_features[receiver][\"in_txs\"] += 1\n",
    "        account_features[receiver][\"in_amount\"] += amount\n",
    "        if timestamp < account_features[receiver][\"first_active\"]:\n",
    "            account_features[receiver][\"first_active\"] = timestamp\n",
    "        if timestamp > account_features[receiver][\"last_active\"]:\n",
    "            account_features[receiver][\"last_active\"] = timestamp\n",
    "\n",
    "\n",
    "    # 计算存活周期和平均信息，打标签\n",
    "    for account, features in account_features.items():\n",
    "        features[\"total_txs\"] = features[\"in_txs\"] + features[\"out_txs\"]\n",
    "        features[\"balance\"] = features[\"in_amount\"] - features[\"out_amount\"]\n",
    "        features[\"avg_in_amount\"] = features[\"in_amount\"] / features[\"in_txs\"] if features[\"in_txs\"] > 0 else features[\"in_amount\"]\n",
    "        features[\"avg_out_amount\"] = features[\"out_amount\"] / features[\"out_txs\"] if features[\"out_txs\"] > 0 else features[\"out_amount\"]\n",
    "        features[\"lifespan\"] = features[\"last_active\"] - features[\"first_active\"]\n",
    "        features[\"freq_in\"] = features[\"in_txs\"] / (features[\"lifespan\"] / 86400) if features[\"lifespan\"] > 0 else features[\"in_txs\"]  # xx笔交易/天\n",
    "        features[\"freq_out\"] = features[\"out_txs\"] / (features[\"lifespan\"] / 86400) if features[\"lifespan\"] > 0 else features[\"out_txs\"]\n",
    "        features[\"freq\"] = features[\"freq_in\"] + features[\"freq_out\"]\n",
    "    \n",
    "    if not is_df:\n",
    "        return account_features\n",
    "\n",
    "    df_account_features = pd.DataFrame(list(account_features.values()), index = list(account_features.keys()))\n",
    "    df_account_features = df_account_features.drop(['first_active', 'last_active'], axis=1)\n",
    "    \n",
    "    return df_account_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9846407a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_edge_features(df_tx):\n",
    "    # 按'From'和'To'列进行分组，并聚合Value列的和、交易数量和时间跨度\n",
    "    edge_features = df_tx.groupby(['From', 'To']).agg(\n",
    "            Sum_amount=('Value', 'sum'),  # 将 'Value' 列求和并重命名为 'Sum_amount'\n",
    "            Txs=('TimeStamp', 'count'),  # 计算 'TimeStamp' 的数量\n",
    "            Time_min=('TimeStamp', 'min'),  # 计算 'TimeStamp' 的最小值\n",
    "            Time_max=('TimeStamp', 'max')   # 计算 'TimeStamp' 的最大值\n",
    "        ).rename(columns={'Value': 'Amount'}).reset_index()\n",
    "\n",
    "    edge_features['TimeSpan'] = edge_features['Time_max'] - edge_features['Time_min']\n",
    "\n",
    "    edge_features = edge_features[['From', 'To', 'Sum_amount', 'Txs', 'TimeSpan']]\n",
    "\n",
    "    edge_features[\"Avg_amount\"] = edge_features[\"Sum_amount\"] / edge_features[\"Txs\"]\n",
    "    edge_features[\"TimeSpan\"] = edge_features[\"TimeSpan\"].replace(0, 1)  # 单位：秒\n",
    "\n",
    "    return edge_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1ffb5e",
   "metadata": {},
   "source": [
    "## 图构建"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f57ff9d",
   "metadata": {},
   "source": [
    "### 静态图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6c590b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "class txGraph(Data):\n",
    "    def __init__(self, tx, feature, train_test_edges, seed=seed):\n",
    "        super().__init__()\n",
    "        \n",
    "        nodes_dict = {value: idx for idx, value in enumerate(feature.index.tolist())}\n",
    "        \n",
    "        edges = self.edge_idx_map(nodes_dict, set(zip(tx[\"From\"].tolist(), tx[\"To\"].tolist())))\n",
    "        train_edges_pos = self.edge_idx_map(nodes_dict, train_test_edges['train_edges_pos'])\n",
    "        train_edges_neg = self.edge_idx_map(nodes_dict, train_test_edges['train_edges_false'])\n",
    "        test_edges_pos = self.edge_idx_map(nodes_dict, train_test_edges['test_edges_pos'])\n",
    "        test_edges_neg = self.edge_idx_map(nodes_dict, train_test_edges['test_edges_false'])\n",
    "        \n",
    "        self.edge_index = torch.tensor(edges, dtype=torch.long).t()\n",
    "        self.train_edge_pos_index = torch.tensor(train_edges_pos, dtype=torch.long).t()\n",
    "        self.train_edge_neg_index = torch.tensor(train_edges_neg, dtype=torch.long).t()\n",
    "        self.test_edge_pos_index = torch.tensor(test_edges_pos, dtype=torch.long).t()\n",
    "        self.test_edge_neg_index = torch.tensor(test_edges_neg, dtype=torch.long).t()\n",
    "\n",
    "        self.time = torch.tensor(tx[\"TimeStamp\"].tolist(), dtype=torch.long)\n",
    "\n",
    "        self.x = torch.tensor(feature.values)  # 节点特征\n",
    "        self.num_nodes = self.x.shape[0]  # 节点数量\n",
    "        \n",
    "    def edge_idx_map(self, nodes_dict, edges):\n",
    "        \n",
    "        return list(map(lambda x: (nodes_dict[x[0]], nodes_dict[x[1]]), list(edges)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2522f292",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = txGraph(df_emb, df_emb_account_features_normalized, train_test_edges)\n",
    "\n",
    "graph_path = '..\\\\code_tracking_eth\\\\graphs\\\\'\n",
    "with open(graph_path + f'LPsubG{graph_id}_static_graph_with_node_features_{emb_ratio}.pkl', 'wb') as f:\n",
    "    pickle.dump(data, f)\n",
    "    \n",
    "# with open(data_path + 'LPsubG3_static_graph_with_node_features.pkl', 'rb') as f:\n",
    "#     data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1f53c061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of nodes: 4767\n",
      "Dimension of node features: 12\n",
      "Num of edges: 8210\n",
      "Num of train edges for LP: 587\n",
      "Num of test edges for LP: 587\n"
     ]
    }
   ],
   "source": [
    "print(\"Num of nodes:\", data.num_nodes)\n",
    "print(\"Dimension of node features:\", data.x.shape[1])\n",
    "print(\"Num of edges:\", data.edge_index.shape[1])\n",
    "print(\"Num of train edges for LP:\", data.train_edge_pos_index.shape[1])\n",
    "print(\"Num of test edges for LP:\", data.test_edge_pos_index.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6420da3d",
   "metadata": {},
   "source": [
    "### 动态图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "824351b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置时间步数量\n",
    "temporal_steps = 8\n",
    "# df_emb.drop(0, inplace = True) # 针对EthereumG1\n",
    "\n",
    "overlap_ratio = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58aabb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_df_by_temporal_steps_with_overlap(df, temporal_steps=temporal_steps, overlap_ratio=overlap_ratio):\n",
    "    \n",
    "    # 计算时间跨度\n",
    "    start_time = df['TimeStamp'].min()\n",
    "    end_time = df['TimeStamp'].max()\n",
    "    time_span = end_time - start_time  # 总时间跨度，单位为秒\n",
    "    \n",
    "    # 计算滑动窗口大小 W 和步长 S\n",
    "    window_size = time_span / (temporal_steps * (1 - overlap_ratio) + overlap_ratio)\n",
    "    step_size = window_size * (1 - overlap_ratio)\n",
    "    \n",
    "    # 存储时间快照\n",
    "    snapshots = []\n",
    "    \n",
    "    # 初始化滑动窗口的起始时间\n",
    "    current_start_time = start_time\n",
    "    \n",
    "    for i in range(temporal_steps):\n",
    "        # 计算当前快照的结束时间\n",
    "        current_end_time = current_start_time + window_size\n",
    "        \n",
    "        # 提取当前时间段的数据\n",
    "        snapshot = df[(df['TimeStamp'] >= current_start_time) & (df['TimeStamp'] <= current_end_time)]\n",
    "        snapshots.append(snapshot)\n",
    "        \n",
    "        # 更新下一次快照的起始时间\n",
    "        current_start_time = current_start_time + step_size  # 有重叠部分\n",
    "    \n",
    "    # 输出每个子 DataFrame 的大小\n",
    "    for i, sub_df in enumerate(snapshots):\n",
    "        print(f\"TimeStep {i} size: {sub_df.shape[0]} rows\")\n",
    "    \n",
    "    return snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38796eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_df_by_temporal_steps(df, temporal_steps=temporal_steps):\n",
    "    \"\"\"\n",
    "    将 DataFrame 按照时间戳分成多个时间步区间，并输出每个子 DataFrame 的大小。\n",
    "    \"\"\"\n",
    "\n",
    "    # 获取时间戳的最小值和最大值\n",
    "    min_timestamp = df['TimeStamp'].min()\n",
    "    max_timestamp = df['TimeStamp'].max()\n",
    "\n",
    "    # 使用 pandas 的 cut 函数来划分时间戳\n",
    "    time_bins = np.linspace(min_timestamp, max_timestamp, temporal_steps + 1)  # 创建时间步区间的边界\n",
    "    df['TimeStep'] = pd.cut(df['TimeStamp'], bins=time_bins, labels=False, include_lowest=True)\n",
    "\n",
    "    # 按 TimeStep 列分组并拆分为多个子 DataFrame\n",
    "    df_list = [df[df['TimeStep'] == i] for i in range(temporal_steps)]\n",
    "\n",
    "    # 输出每个子 DataFrame 的大小\n",
    "    for i, sub_df in enumerate(df_list):\n",
    "        print(f\"TimeStep {i} size: {sub_df.shape[0]} rows\")\n",
    "\n",
    "    return df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "876be5fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimeStep 0 size: 75100 rows\n",
      "TimeStep 1 size: 78082 rows\n",
      "TimeStep 2 size: 75503 rows\n",
      "TimeStep 3 size: 118812 rows\n",
      "TimeStep 4 size: 170545 rows\n",
      "TimeStep 5 size: 177593 rows\n",
      "TimeStep 6 size: 213917 rows\n",
      "TimeStep 7 size: 133541 rows\n"
     ]
    }
   ],
   "source": [
    "# df_emb_list = split_df_by_temporal_steps(df_emb.copy())\n",
    "df_emb_list = split_df_by_temporal_steps_with_overlap(df_emb.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f263df5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_node_features_for_temporal_steps(df_list, extract_account_features, all_nodes=None):\n",
    "     # 如果没有提供 all_nodes，自动从 df_list 中提取所有节点\n",
    "    if all_nodes is None:\n",
    "        all_nodes = set()\n",
    "        for sub_df in df_list:\n",
    "            all_nodes.update(set(sub_df['From']).union(set(sub_df['To'])))\n",
    "\n",
    "    df_features_list = []\n",
    "\n",
    "    # 为每个子 DataFrame 提取节点特征\n",
    "    for i, sub_df in enumerate(df_list):\n",
    "        # 提取当前时间步的节点特征\n",
    "        node_features = extract_account_features(sub_df, False)\n",
    "        \n",
    "        # 获取节点特征的默认值\n",
    "        null_feature = {key: 0 for key in list(node_features.values())[0]}\n",
    "        \n",
    "        # 创建一个特征矩阵，其中每个节点的特征为空值时设置为 null_feature\n",
    "        df_features = {}\n",
    "        for node in all_nodes:\n",
    "            df_features[node] = node_features.get(node, null_feature)\n",
    "        \n",
    "        # 将特征字典转换为 DataFrame\n",
    "        df_features = pd.DataFrame(list(df_features.values()), index=list(df_features.keys()))\n",
    "        \n",
    "        df_features = df_features.drop(['first_active', 'last_active'], axis=1, errors='ignore')\n",
    "        \n",
    "        non_zero_indices = list(node_features.keys())\n",
    "        df_non_zero_features = df_features.loc[non_zero_indices]\n",
    "        \n",
    "        # 标准化非零特征\n",
    "        df_non_zero_features_normalized = (df_non_zero_features - df_non_zero_features.mean()) / df_non_zero_features.std(ddof=0)\n",
    "        df_features.loc[non_zero_indices] = df_non_zero_features_normalized\n",
    "        \n",
    "        df_features_list.append(df_features)\n",
    "    \n",
    "    return df_features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5709a591",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nodes = set(df_emb['From']).union(set(df_emb['To'])) \n",
    "df_emb_account_features_list = extract_node_features_for_temporal_steps(df_emb_list, extract_account_features, all_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d9c09e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>in_txs</th>\n",
       "      <th>in_amount</th>\n",
       "      <th>out_txs</th>\n",
       "      <th>out_amount</th>\n",
       "      <th>total_txs</th>\n",
       "      <th>balance</th>\n",
       "      <th>avg_in_amount</th>\n",
       "      <th>avg_out_amount</th>\n",
       "      <th>lifespan</th>\n",
       "      <th>freq_in</th>\n",
       "      <th>freq_out</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48.993363</td>\n",
       "      <td>32.259604</td>\n",
       "      <td>2.206775</td>\n",
       "      <td>57.478909</td>\n",
       "      <td>27.267396</td>\n",
       "      <td>-6.179811e+00</td>\n",
       "      <td>-0.045635</td>\n",
       "      <td>0.347977</td>\n",
       "      <td>2.790806</td>\n",
       "      <td>0.983073</td>\n",
       "      <td>-0.153021</td>\n",
       "      <td>0.111685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.034835</td>\n",
       "      <td>-0.040161</td>\n",
       "      <td>-0.039829</td>\n",
       "      <td>-0.061549</td>\n",
       "      <td>-0.051371</td>\n",
       "      <td>1.257447e-07</td>\n",
       "      <td>-0.099136</td>\n",
       "      <td>-0.079331</td>\n",
       "      <td>-0.273542</td>\n",
       "      <td>-0.211888</td>\n",
       "      <td>-0.177015</td>\n",
       "      <td>-0.214598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.070031</td>\n",
       "      <td>0.008434</td>\n",
       "      <td>-0.047111</td>\n",
       "      <td>0.012926</td>\n",
       "      <td>-0.075722</td>\n",
       "      <td>1.024562e-07</td>\n",
       "      <td>0.255882</td>\n",
       "      <td>0.270840</td>\n",
       "      <td>-0.654231</td>\n",
       "      <td>0.664688</td>\n",
       "      <td>-0.053546</td>\n",
       "      <td>0.120802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.006227</td>\n",
       "      <td>-0.017467</td>\n",
       "      <td>-0.017981</td>\n",
       "      <td>-0.026769</td>\n",
       "      <td>-0.011800</td>\n",
       "      <td>1.965016e-07</td>\n",
       "      <td>-0.078319</td>\n",
       "      <td>-0.063163</td>\n",
       "      <td>-0.050789</td>\n",
       "      <td>-0.209972</td>\n",
       "      <td>-0.176035</td>\n",
       "      <td>-0.213220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.081763</td>\n",
       "      <td>-0.041259</td>\n",
       "      <td>-0.036187</td>\n",
       "      <td>0.089233</td>\n",
       "      <td>-0.072678</td>\n",
       "      <td>-1.172000e-01</td>\n",
       "      <td>-0.101108</td>\n",
       "      <td>0.094629</td>\n",
       "      <td>-0.606888</td>\n",
       "      <td>-0.222291</td>\n",
       "      <td>-0.166600</td>\n",
       "      <td>-0.207800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103911</th>\n",
       "      <td>-0.081763</td>\n",
       "      <td>-0.041259</td>\n",
       "      <td>-0.047111</td>\n",
       "      <td>-0.063213</td>\n",
       "      <td>-0.081809</td>\n",
       "      <td>-1.453902e-05</td>\n",
       "      <td>-0.101108</td>\n",
       "      <td>-0.081842</td>\n",
       "      <td>-0.655351</td>\n",
       "      <td>-0.222291</td>\n",
       "      <td>-0.175963</td>\n",
       "      <td>-0.216294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103912</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103913</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103914</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103915</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37654 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           in_txs  in_amount   out_txs  out_amount  total_txs       balance  \\\n",
       "1       48.993363  32.259604  2.206775   57.478909  27.267396 -6.179811e+00   \n",
       "4       -0.034835  -0.040161 -0.039829   -0.061549  -0.051371  1.257447e-07   \n",
       "5       -0.070031   0.008434 -0.047111    0.012926  -0.075722  1.024562e-07   \n",
       "6        0.006227  -0.017467 -0.017981   -0.026769  -0.011800  1.965016e-07   \n",
       "7       -0.081763  -0.041259 -0.036187    0.089233  -0.072678 -1.172000e-01   \n",
       "...           ...        ...       ...         ...        ...           ...   \n",
       "103911  -0.081763  -0.041259 -0.047111   -0.063213  -0.081809 -1.453902e-05   \n",
       "103912   0.000000   0.000000  0.000000    0.000000   0.000000  0.000000e+00   \n",
       "103913   0.000000   0.000000  0.000000    0.000000   0.000000  0.000000e+00   \n",
       "103914   0.000000   0.000000  0.000000    0.000000   0.000000  0.000000e+00   \n",
       "103915   0.000000   0.000000  0.000000    0.000000   0.000000  0.000000e+00   \n",
       "\n",
       "        avg_in_amount  avg_out_amount  lifespan   freq_in  freq_out      freq  \n",
       "1           -0.045635        0.347977  2.790806  0.983073 -0.153021  0.111685  \n",
       "4           -0.099136       -0.079331 -0.273542 -0.211888 -0.177015 -0.214598  \n",
       "5            0.255882        0.270840 -0.654231  0.664688 -0.053546  0.120802  \n",
       "6           -0.078319       -0.063163 -0.050789 -0.209972 -0.176035 -0.213220  \n",
       "7           -0.101108        0.094629 -0.606888 -0.222291 -0.166600 -0.207800  \n",
       "...               ...             ...       ...       ...       ...       ...  \n",
       "103911      -0.101108       -0.081842 -0.655351 -0.222291 -0.175963 -0.216294  \n",
       "103912       0.000000        0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "103913       0.000000        0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "103914       0.000000        0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "103915       0.000000        0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "\n",
       "[37654 rows x 12 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_emb_account_features_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f6473ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class tempTxGraph(Data):\n",
    "    def __init__(self, tx_list, feature_list, all_nodes, train_test_edges, seed=seed):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.temporal_steps = len(tx_list)\n",
    "\n",
    "        nodes_dict = {value: idx for idx, value in enumerate(all_nodes)}\n",
    "        \n",
    "        # 边索引\n",
    "        self.edge_indexs = []\n",
    "        for tx in tx_list:\n",
    "            edges = self.edge_idx_map(nodes_dict, set(zip(tx[\"From\"].tolist(), tx[\"To\"].tolist())))\n",
    "            self.edge_indexs.append(torch.tensor(edges, dtype=torch.long).t())\n",
    "        \n",
    "        train_edges_pos = self.edge_idx_map(nodes_dict, train_test_edges['train_edges_pos'])\n",
    "        train_edges_neg = self.edge_idx_map(nodes_dict, train_test_edges['train_edges_false'])\n",
    "        test_edges_pos = self.edge_idx_map(nodes_dict, train_test_edges['test_edges_pos'])\n",
    "        test_edges_neg = self.edge_idx_map(nodes_dict, train_test_edges['test_edges_false'])\n",
    "        self.train_edge_pos_index = torch.tensor(train_edges_pos, dtype=torch.long).t()\n",
    "        self.train_edge_neg_index = torch.tensor(train_edges_neg, dtype=torch.long).t()\n",
    "        self.test_edge_pos_index = torch.tensor(test_edges_pos, dtype=torch.long).t()\n",
    "        self.test_edge_neg_index = torch.tensor(test_edges_neg, dtype=torch.long).t()\n",
    "\n",
    "        # 节点特征\n",
    "        self.x = []\n",
    "        for feature in feature_list:\n",
    "            self.x.append(torch.tensor(feature.values))\n",
    "        \n",
    "    def edge_idx_map(self, nodes_dict, edges):\n",
    "        \n",
    "        return list(map(lambda x: (nodes_dict[x[0]], nodes_dict[x[1]]), list(edges)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "568240eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tempTxGraph(df_emb_list, df_emb_account_features_list, all_nodes, train_test_edges)\n",
    "\n",
    "graph_path = 'graphs\\\\'\n",
    "\n",
    "# with open(graph_path + f'LPsubG{graph_id}_temp_graph_{data.temporal_steps}_overlap_{overlap_ratio}_with_node_features_{emb_ratio}.pkl', 'wb') as f:\n",
    "#     pickle.dump(data, f)\n",
    "    \n",
    "    \n",
    "with open(graph_path + f'LPsubG{graph_id}_temp_graph_{data.temporal_steps}_overlap_{overlap_ratio}_with_node_features_{emb_ratio}.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "90f25d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of temporal steps: 8\n",
      "Num of nodes: [37654, 37654, 37654, 37654, 37654, 37654, 37654, 37654]\n",
      "Dimension of node features: [12, 12, 12, 12, 12, 12, 12, 12]\n",
      "Num of edges: [8023, 3166, 2650, 5685, 10445, 12667, 19076, 5470]\n",
      "Num of train edges for LP: 2338\n",
      "Num of test edges for LP: 2339\n"
     ]
    }
   ],
   "source": [
    "print(\"Num of temporal steps:\", data.temporal_steps)\n",
    "print(\"Num of nodes:\", [feature.shape[0] for feature in data.x])\n",
    "print(\"Dimension of node features:\", [feature.shape[1] for feature in data.x])\n",
    "print(\"Num of edges:\", [edge_index.shape[1] for edge_index in data.edge_indexs])\n",
    "print(\"Num of train edges for LP:\", data.train_edge_pos_index.shape[1])\n",
    "print(\"Num of test edges for LP:\", data.test_edge_pos_index.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1accbe9",
   "metadata": {},
   "source": [
    "动态边特征:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "abbcd063",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_edge_features_for_temporal_steps(df_list, extract_edge_features, train_test_edges):\n",
    "    # 获取用于训练和测试的边集\n",
    "    train_edges_pos = train_test_edges['train_edges_pos']\n",
    "    train_edges_neg = train_test_edges['train_edges_false']\n",
    "    test_edges_pos = train_test_edges['test_edges_pos']\n",
    "    test_edges_neg = train_test_edges['test_edges_false'] \n",
    "    \n",
    "    train_features = []\n",
    "    test_features = []\n",
    "    \n",
    "    for t, df in enumerate(df_list):\n",
    "        # 提取当前时间步的边特征\n",
    "        df_features = extract_edge_features(df)\n",
    "        \n",
    "        train_features_t = []\n",
    "        test_features_t = []\n",
    "        \n",
    "        # 获取训练集的正负边特征\n",
    "        for i, edge in enumerate(train_edges_pos + train_edges_neg):\n",
    "            from_node, to_node = edge\n",
    "            edge_data = df_features[(df_features['From'] == from_node) & (df_features['To'] == to_node)]\n",
    "\n",
    "            if len(edge_data) == 0:  # 如果df中没有这个边，设置边特征为全0\n",
    "                edge_feature = np.zeros(df_features.shape[1] - 2)  # 忽略'From' 和 'To'列\n",
    "            else:\n",
    "                edge_feature = edge_data.iloc[0, 2:].values  # 边特征从第三列开始\n",
    "                \n",
    "            train_features_t.append(edge_feature)\n",
    "\n",
    "        # 获取测试集的正负边特征\n",
    "        for i, edge in enumerate(test_edges_pos + test_edges_neg):\n",
    "            from_node, to_node = edge\n",
    "            edge_data = df_features[(df_features['From'] == from_node) & (df_features['To'] == to_node)]\n",
    "\n",
    "            if len(edge_data) == 0:  # 如果df中没有这个边，设置边特征为全0\n",
    "                edge_feature = np.zeros(df_features.shape[1] - 2)  # 忽略'From' 和 'To'列\n",
    "            else:\n",
    "                edge_feature = edge_data.iloc[0, 2:].values  # 假设边特征从第三列开始\n",
    "\n",
    "            test_features_t.append(edge_feature)\n",
    "        \n",
    "        train_features.append(train_features_t)\n",
    "        test_features.append(test_features_t)\n",
    "    \n",
    "    train_features = np.array(train_features)\n",
    "    train_labels = np.concatenate([np.ones((len(train_edges_pos), 1)), np.zeros((len(train_edges_neg), 1))], axis=0)\n",
    "    test_features = np.array(test_features)\n",
    "    test_labels = np.concatenate([np.ones((len(test_edges_pos), 1)), np.zeros((len(test_edges_neg), 1))], axis=0)\n",
    "    \n",
    "    print(\"Shape of Train Features:\", train_features.shape)\n",
    "    print(\"Shape of Train Labels:\", train_labels.shape)\n",
    "    print(\"Shape of Test Features:\", test_features.shape)\n",
    "    print(\"Shape of Test Labels:\", test_labels.shape)\n",
    "    \n",
    "    return train_features, train_labels, test_features, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b629ef7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Train Features: (8, 4676, 4)\n",
      "Shape of Train Labels: (4676, 1)\n",
      "Shape of Test Features: (8, 4678, 4)\n",
      "Shape of Test Labels: (4678, 1)\n"
     ]
    }
   ],
   "source": [
    "train_edges_features, train_edges_labels, test_edges_features, test_edges_labels = extract_edge_features_for_temporal_steps(df_emb_list, extract_edge_features, train_test_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "416197c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(features):\n",
    "    # 获取features的形状：[时间步数, 边数量, 特征维度]\n",
    "    num_timesteps, num_edges, num_features = features.shape\n",
    "    \n",
    "    # 对每个时间步的特征进行标准化\n",
    "    for t in range(num_timesteps):\n",
    "        # 获取当前时间步的所有边特征\n",
    "        features_t = features[t]\n",
    "        \n",
    "        # 排除值全为0的特征\n",
    "        nonzero_mask = np.any(features_t != 0, axis=1)  # 过滤掉全为0的特征\n",
    "        nonzero_features = features_t[nonzero_mask]\n",
    "        \n",
    "        if len(nonzero_features) != 0:\n",
    "            # 标准化非零特征\n",
    "            nonzero_features_normalized = (nonzero_features - nonzero_features.mean()) / nonzero_features.std(ddof=0)      \n",
    "            features_t[nonzero_mask] = nonzero_features_normalized\n",
    "        \n",
    "        # 将标准化后的结果更新到features中\n",
    "        features[t] = features_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9292653c",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize(train_edges_features)\n",
    "normalize(test_edges_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2566ad99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 写\n",
    "\n",
    "# np.save(data_path + f'LPsubG{graph_id}_temp_{temporal_steps}_overlap_{overlap_ratio}_train_edges_features_{emb_ratio}.npy', train_edges_features)\n",
    "# np.save(data_path + f'LPsubG{graph_id}_temp_{temporal_steps}_overlap_{overlap_ratio}_train_edges_labels_{emb_ratio}.npy', train_edges_labels)\n",
    "# np.save(data_path + f'LPsubG{graph_id}_temp_{temporal_steps}_overlap_{overlap_ratio}_test_edges_features_{emb_ratio}.npy', test_edges_features)\n",
    "# np.save(data_path + f'LPsubG{graph_id}_temp_{temporal_steps}_overlap_{overlap_ratio}_test_edges_labels_{emb_ratio}.npy', test_edges_labels)\n",
    "\n",
    "# 读\n",
    "train_edges_features = np.load(data_path + f'LPsubG{graph_id}_temp_{temporal_steps}_train_edges_features_{emb_ratio}.npy')\n",
    "train_edges_labels = np.load(data_path + f'LPsubG{graph_id}_temp_{temporal_steps}_train_edges_labels_{emb_ratio}.npy')\n",
    "test_edges_features = np.load(data_path + f'LPsubG{graph_id}_temp_{temporal_steps}_test_edges_features_{emb_ratio}.npy')\n",
    "test_edges_labels = np.load(data_path + f'LPsubG{graph_id}_temp_{temporal_steps}_test_edges_labels_{emb_ratio}.npy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
